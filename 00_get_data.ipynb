{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from library.utilities import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lists of selected cable news shows\n",
    "fox = ['cavuto', 'thefive', 'baier', 'greta', 'kelly', 'oreilly', 'hannity']\n",
    "cnn = ['tapper', 'blitzer', 'burnett', 'cooper', 'lemon']\n",
    "msnbc = ['mtpdaily', 'wadr', 'matthews', 'hayes', 'maddow', 'odonnell']\n",
    "talking_heads = fox + cnn + msnbc\n",
    "\n",
    "for head in talking_heads:\n",
    "    path = os.path.join('data', head)\n",
    "    mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FOX\n",
    "\n",
    "# kelly\n",
    "url = 'http://www.foxnews.com/shows/the-kelly-file/transcripts.html'\n",
    "pages = range(2, 70)\n",
    "dst = 'data/kelly/links_list.pickle'\n",
    "#get_fox_links_1(url, pages, dst)\n",
    "\n",
    "# oreilly\n",
    "base_url = 'http://www.foxnews.com/shows/the-oreilly-factor/transcripts.html'\n",
    "pages = range(0, 20, 10) #700\n",
    "pickle_dst = 'data/oreilly/links_list2.pickle'\n",
    "get_fox_links(base_url, pages, pickle_dst)\n",
    "#http://www.foxnews.com/transcript/2016/05/05/trump-on-potential-vp-picks-have-lot-candidates/\n",
    "\n",
    "# hannity\n",
    "base_url = 'http://www.foxnews.com/on-air/hannity/transcripts'\n",
    "pages = range(1, 70)\n",
    "pickle_dst = 'data/hannity/links_list.pickle'\n",
    "#get_fox_links(base_url, pages, pickle_dst)\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# CNN\n",
    "\n",
    "# cooper ... just go to transcripts page, save entire webpage, then extract targeted links\n",
    "html_file = 'data/cooper/cooper.htm'\n",
    "pickle_dst = 'data/cooper/links_list.pickle'\n",
    "#get_cnn_links(html_file, pickle_dst)\n",
    "\n",
    "# burnett ... just go to transcripts page, save entire webpage, then extract targeted links\n",
    "html_file = 'data/burnett/burnett.htm'\n",
    "pickle_dst = 'data/burnett/links_list.pickle'\n",
    "#get_cnn_links(html_file, pickle_dst)\n",
    "\n",
    "# blitzer ... used a different approach for this set of cnn transcript links, same outcome though\n",
    "url = 'http://www.cnn.com/TRANSCRIPTS/sitroom.html'\n",
    "pickle_dst = 'data/blitzer/blitzer_half.pickle'\n",
    "#half_links = get_cnn_links(url, pickle_dst)\n",
    "#blitzer_links = ['http://www.cnn.com' + x for x in half_links]\n",
    "#pickle.dump(blitzer_links, open('data/blitzer/blitzer.pickle', \"wb\"))\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# MSNBC\n",
    "years = range(2015, 2017); years\n",
    "months = range(1, 13); months\n",
    "pages = []\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        page = str(year) + '/' + str(month)\n",
    "        pages.append(page)\n",
    "pages = pages[:-4]\n",
    "\n",
    "# maddow\n",
    "base_url = 'http://www.msnbc.com/transcripts/rachel-maddow-show/'\n",
    "filter_str = '/transcripts/rachel-maddow-show/2'\n",
    "pickle_dst = 'data/maddow/links_list.pickle'\n",
    "#get_msnbc_links(base_url, pickle_dst, pages)\n",
    "\n",
    "\n",
    "# odonnel\n",
    "base_url = 'http://www.msnbc.com/transcripts/the-last-word/'\n",
    "filter_str = '/transcripts/the-last-word/2'\n",
    "pickle_dst = 'data/odonnell/links_list.pickle'\n",
    "#get_msnbc_links(base_url, pickle_dst, pages)\n",
    "\n",
    "\n",
    "# hayes\n",
    "base_url = 'http://www.msnbc.com/transcripts/all-in/'\n",
    "filter_str = '/transcripts/all-in/2'\n",
    "pickle_dst = 'data/hayes/links_list.pickle'\n",
    "#get_msnbc_links(base_url, pickle_dst, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(get_pickle('data/oreilly/links_list_old.pickle')), len(get_pickle('data/oreilly/links_list_old2.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make datatable of all the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fox table of links\n",
    "fox_hosts = ['kelly', 'oreilly', 'hannity']\n",
    "fox_to_df(fox_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datatable.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
